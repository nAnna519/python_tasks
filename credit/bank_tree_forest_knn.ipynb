{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "\n",
    "data = data.dropna()\n",
    "numeric_data = data.drop(['record_id'], axis=1)\n",
    "# numeric_data = numeric_data.sort_values(['emp_length'])\n",
    "numeric_data['term'] = pd.factorize(numeric_data['term'])[0]\n",
    "\n",
    "numeric_data['emp_length'] = numeric_data['emp_length'].map({'< 1 year': 1, '1 year': 2, '2 years': 3,  '3 years': 4,  '4 years': 5,  '5 years': 6,  '6 years': 7,  '7 years': 8,  '8 years': 9,  '9 years': 10,  '10+ years': 11})\n",
    "\n",
    "numeric_data['verification_status'] = numeric_data['verification_status'].map({'Not Verified': 0, 'Verified': 1, 'Source Verified': 2})\n",
    "\n",
    "numeric_data['application_type'] = pd.factorize(numeric_data['application_type'])[0]\n",
    "\n",
    "numeric_data['initial_list_status'] = pd.factorize(numeric_data['initial_list_status'])[0]\n",
    "\n",
    "numeric_data['addr_state'] = pd.factorize(numeric_data['addr_state'])[0]\n",
    "    \n",
    "# numeric_data['addr_state'] = pd.factorize(numeric_data['addr_state'])[0]\n",
    "\n",
    "numeric_data['zip_code'] = (numeric_data['zip_code'].str[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_data['emp_length'].fillna(0, inplace=True)\n",
    "\n",
    "numeric_data['emp_title'].fillna('0', inplace=True)\n",
    "\n",
    "numeric_data['mths_since_last_delinq'].fillna(numeric_data['mths_since_last_delinq'].notnull().min(), inplace=True)\n",
    "\n",
    "numeric_data['collections_12_mths_ex_med'].fillna(numeric_data['collections_12_mths_ex_med'].notnull().max(), inplace=True)\n",
    "\n",
    "numeric_data['revol_util'].fillna(numeric_data['revol_util'].notnull().mean(), inplace=True)\n",
    "\n",
    "numeric_data['tot_coll_amt'].fillna(numeric_data['tot_coll_amt'].notnull().min(), inplace=True)\n",
    "\n",
    "numeric_data['tot_cur_bal'].fillna(numeric_data['tot_cur_bal'].notnull().min(), inplace=True)\n",
    "\n",
    "numeric_data['total_rev_hi_lim'].fillna(numeric_data['total_rev_hi_lim'].notnull().min(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def month_to_decimal(month):\n",
    "    month_dict = {'Jan':0, 'Feb':1/12., 'Mar':2/12., 'Apr':3/12., 'May':4/12., 'Jun':5/12., \n",
    "     'Jul':6/12., 'Aug':7/12., 'Sep':8/12., 'Oct':9/12., 'Nov':10/12., 'Dec':11/12.}\n",
    "    return month_dict[month]\n",
    "\n",
    "def convert_date(month_year):\n",
    "    month_and_year = month_year.split('-')\n",
    "    return float(month_and_year[1]) + month_to_decimal(month_and_year[0])\n",
    "numeric_data['issue_d'] = numeric_data['issue_d'].map(convert_date)\n",
    "numeric_data['earliest_cr_line'] = numeric_data['earliest_cr_line'].map(convert_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, scale\n",
    "\n",
    "\n",
    "le = LabelEncoder()\n",
    "# print(str(numeric_data['grade'].values))\n",
    "numeric_data[numeric_data['grade'] == 0] = '0'\n",
    "le.fit(numeric_data.grade.astype(str))\n",
    "# print(le.classes_)\n",
    "# numeric_data.info()\n",
    "numeric_data['grade_le'] = le.transform((numeric_data['grade'].values))\n",
    "\n",
    "le.fit(numeric_data.sub_grade.astype(str))\n",
    "numeric_data['sub_grade_le'] = le.transform(numeric_data['sub_grade'].values)\n",
    "\n",
    "le.fit(numeric_data.emp_title.astype(str))\n",
    "numeric_data['emp_title_le'] = le.transform(numeric_data['emp_title'].values)\n",
    "\n",
    "# le.fit(numeric_data.addr_state.astype(str))\n",
    "# numeric_data['addr_state_le'] = le.transform(numeric_data['addr_state'].values)\n",
    "\n",
    "le.fit(numeric_data.pymnt_plan.astype(str))\n",
    "numeric_data['pymnt_plan_le'] = le.transform(numeric_data['pymnt_plan'].values)\n",
    "\n",
    "le.fit(numeric_data.purpose.astype(str))\n",
    "numeric_data['purpose_le'] = le.transform(numeric_data['purpose'].values)\n",
    "\n",
    "ohe = OneHotEncoder()\n",
    "new_ohe_features = ohe.fit(numeric_data.home_ownership.values.reshape(-1, 1))\n",
    "data['home_ownership_ohe'] = ohe.transform(numeric_data.home_ownership.values.reshape(-1, 1))\n",
    "\n",
    "numeric_data = numeric_data.drop(['grade', 'sub_grade', 'purpose', 'emp_title', 'pymnt_plan', 'home_ownership'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NikitsinskayaH\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: Data with input dtype int32, int64, object were all converted to float64 by the scale function.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "X = numeric_data.drop(['loan_status'], axis=1)\n",
    "y = numeric_data['loan_status']\n",
    "# type(numeric_data['zip_code'].astype(int))\n",
    "X = scale(X)\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "X, y = ros.fit_resample(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of  10 | elapsed:  2.6min remaining:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:  3.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'min_samples_leaf': 3}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "forest_tree = RandomForestClassifier(n_estimators=100)\n",
    "forest_tree.fit(X_train, y_train)\n",
    "\n",
    "forest_params = {'min_samples_leaf': [3, 5]}\n",
    "\n",
    "forest_grid = GridSearchCV(forest_tree, forest_params,\n",
    "cv=5, n_jobs=-1,\n",
    "verbose=True)\n",
    "\n",
    "forest_grid.fit(X_train, y_train)\n",
    "\n",
    "forest_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NikitsinskayaH\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed: 13.0min\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed: 28.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_depth': 9, 'n_estimators': 200}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "forest_tree = RandomForestClassifier(min_samples_leaf=3)\n",
    "forest_tree.fit(X_train, y_train)\n",
    "\n",
    "forest_params = {'n_estimators': [100, 200, 500],\n",
    "                'max_depth':[3, 5, 7, 9]}\n",
    "\n",
    "forest_grid = GridSearchCV(forest_tree, forest_params,\n",
    "cv=5, n_jobs=-1,\n",
    "verbose=True)\n",
    "\n",
    "forest_grid.fit(X_train, y_train)\n",
    "\n",
    "forest_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forest: \n",
      "Recall score: 0.6483192199127534\n",
      "Precision score: 0.6764239976796591\n",
      "Auc score: 0.6686581410395153\n"
     ]
    }
   ],
   "source": [
    "forest_tree = RandomForestClassifier(min_samples_leaf=3, max_depth=9, n_estimators=200)\n",
    "forest_tree.fit(X_train, y_train)\n",
    "preds = forest_tree.predict(X_test)\n",
    "\n",
    "print('Forest: ')\n",
    "\n",
    "print('Recall score: ' + str(metrics.recall_score(y_test, preds)))\n",
    "\n",
    "print('Precision score: ' + str(metrics.precision_score(y_test, preds)))\n",
    "\n",
    "print('Auc score: ' + str(metrics.roc_auc_score(y_test, preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   22.8s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:   43.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_depth': 9, 'min_samples_leaf': 3}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "tree = DecisionTreeClassifier()\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "tree_params = {'max_depth': [3, 5, 7, 9],\n",
    "                'min_samples_leaf': [3, 5, 7]}\n",
    "\n",
    "tree_grid = GridSearchCV(tree, tree_params,\n",
    "cv=5, n_jobs=-1,\n",
    "verbose=True)\n",
    "\n",
    "tree_grid.fit(X_train, y_train)\n",
    "\n",
    "tree_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree: \n",
      "Recall score: 0.6201565306646138\n",
      "Precision score: 0.6731269148639867\n",
      "Auc score: 0.6590800451877741\n"
     ]
    }
   ],
   "source": [
    "preds = tree_grid.predict(X_test)\n",
    "\n",
    "print('Tree: ')\n",
    "\n",
    "print('Recall score: ' + str(metrics.recall_score(y_test, preds)))\n",
    "\n",
    "print('Precision score: ' + str(metrics.precision_score(y_test, preds)))\n",
    "\n",
    "print('Auc score: ' + str(metrics.roc_auc_score(y_test, preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "def euclideanDistance(instance1, instance2):\n",
    "    distance = 0\n",
    "    for x in range(len(instance1)):\n",
    "        distance += (int(instance1[x]) - int(instance2[x])) ** 2\n",
    "    return math.sqrt(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator \n",
    "\n",
    "\n",
    "def getNeighbors(X_train, y_train, X_test, k):\n",
    "    distances = []\n",
    "    length = len(X_test) \n",
    "    neighbors = []\n",
    "    i = 0\n",
    "    for x in X_train:\n",
    "        distance = euclideanDistance(X_test, x)\n",
    "        distances.append((y_train[i], distance))\n",
    "        i += 1\n",
    "    distances.sort(key=operator.itemgetter(1))\n",
    "    for x in range(k):\n",
    "        neighbors.append(distances[x][0])\n",
    "    return neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getResponse(neighbors):\n",
    "    classVotes = {}\n",
    "    for x in range(len(neighbors)):\n",
    "        response = neighbors[x]\n",
    "        if response in classVotes:\n",
    "            classVotes[response] += 1\n",
    "        else:\n",
    "            classVotes[response] = 1\n",
    "    sortedVotes = sorted(classVotes.items(), key = operator.itemgetter(1), reverse=True)\n",
    "    return sortedVotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "k = 3\n",
    "X = numeric_data.drop(['loan_status'], axis=1)\n",
    "y = numeric_data['loan_status']\n",
    "X = scale(X)\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "ros = RandomUnderSampler(random_state=0)\n",
    "X, y = ros.fit_resample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "i = 0\n",
    "for x in X_test:\n",
    "    neighbors = getNeighbors(X_train, y_train, x, k)\n",
    "    if neighbors is not None:\n",
    "        result = getResponse(neighbors)\n",
    "        predictions.append(result[0][0])\n",
    "        print('predicted: ' + str(result))\n",
    "        print('actual: ' + str(y_test[i]))\n",
    "        i += 1\n",
    "print('Own Knn: ')\n",
    "\n",
    "print('Recall score: ' + str(metrics.recall_score(y_test, predictions)))\n",
    "\n",
    "print('Precision score: ' + str(metrics.precision_score(y_test, predictions)))\n",
    "\n",
    "print('Auc score: ' + str(metrics.roc_auc_score(y_test, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
